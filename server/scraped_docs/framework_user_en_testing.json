{
  "route": "framework/user/en/testing",
  "sourceUrl": "https://docs.frappe.io/framework/user/en/testing",
  "title": "Frappe provides some basic tooling to write automated tests. There are some",
  "content": "Frappe provides some basic tooling to write automated tests. There are some\nbasic rules:\n\nTest can be anywhere in your repository but must begin with test_ and\nshould be a .py file.\nThe test runner will automatically build test records for dependent DocTypes\nidentified by the Link type field (Foreign Key).\nFor non-DocType tests, you can write simple unit tests and prefix your file\nnames with test_.\n\nWriting Tests\n\nWhen you create a new DocType (in developer mode), the boilerplate files also\ncontain the test_{doctype}.py file. The test file should handle creating\ndependencies and cleaning them up.\n\nHere is a sample test file referred from test_event.py.\n\nimport frappe\nimport unittest\n\ndef create_events():\n if frappe.flags.test_events_created:\n return\n\n frappe.set_user(\"Administrator\")\n doc = frappe.get_doc({\n \"doctype\": \"Event\",\n \"subject\":\"_Test Event 1\",\n \"starts_on\": \"2014-01-01\",\n \"event_type\": \"Public\"\n }).insert()\n\n doc = frappe.get_doc({\n \"doctype\": \"Event\",\n \"subject\":\"_Test Event 3\",\n \"starts_on\": \"2014-01-01\",\n \"event_type\": \"Public\"\n \"event_individuals\": [{\n \"person\": \"test1@example.com\"\n }]\n }).insert()\n\n frappe.flags.test_events_created = True\n\nclass TestEvent(unittest.TestCase):\n def setUp(self):\n create_events()\n\n def tearDown(self):\n frappe.set_user(\"Administrator\")\n\n def test_allowed_public(self):\n frappe.set_user(\"test1@example.com\")\n doc = frappe.get_doc(\"Event\", frappe.db.get_value(\"Event\",\n {\"subject\":\"_Test Event 1\"}))\n self.assertTrue(frappe.has_permission(\"Event\", doc=doc))\n\n def test_not_allowed_private(self):\n frappe.set_user(\"test1@example.com\")\n doc = frappe.get_doc(\"Event\", frappe.db.get_value(\"Event\",\n {\"subject\":\"_Test Event 2\"}))\n self.assertFalse(frappe.has_permission(\"Event\", doc=doc))\n\nWriting Tests for Commands\n\nTo write tests for your Bench commands, you can group your tests under a\nClass that extends BaseTestCommands from frappe.tests.test_commands and\nunittest.TestCase so that it runs during the bench run-tests command.\n\nFor reference, here is are some tests written for the bench execute command.\n\nclass TestCommands(BaseTestCommands, unittest.TestCase):\n def test_execute(self):\n # test 1: execute a command expecting a numeric output\n self.execute(\"bench --site {site} execute frappe.db.get_database_size\")\n self.assertEqual(self.returncode, 0)\n self.assertIsInstance(float(self.stdout), float)\n\n # test 2: execute a command expecting an errored output as local won't exist\n self.execute(\"bench --site {site} execute frappe.local.site\")\n self.assertEqual(self.returncode, 1)\n self.assertIsNotNone(self.stderr)\n\n # test 3: execute a command with kwargs\n # Note:\n # terminal command has been escaped to avoid .format string replacement\n # The returned value has quotes which have been trimmed for the test\n self.execute(\"\"\"bench --site {site} execute frappe.bold --kwargs '{{\"text\": \"DocType\"}}'\"\"\")\n self.assertEqual(self.returncode, 0)\n self.assertEqual(self.stdout[1:-1], frappe.bold(text='DocType'))\n\nRunning Tests\n\nRunning tests could require additional dependencies specified by apps in their dev-requirements.txt file. Before running tests, make sure all apps have development dependencies installed using bench setup requirements --dev.\n\nRun the following command to run all your tests. It will build all\nthe test dependencies once and run your tests. You should run tests from\nfrappe_bench folder.\n\n# run all tests\nbench --site [sitename] run-tests\n\n# run tests for only frappe app\nbench --site [sitename] run-tests --app frappe\n\n# run tests for the Task doctype\nbench --site [sitename] run-tests --doctype \"Task\"\n\n# run tests for All doctypes in specified Module Def\nbench --site [sitename] run-tests --module-def \"Contacts\"\n\n# run a test using module path\nbench --site [sitename] run-tests --module frappe.tests.test_api\n\n# run a specific test from a test file\nbench --site [sitename] run-tests --module frappe.tests.test_api --test test_insert_many\n\n# run tests without creating test records\nbench --site [sitename] run-tests --skip-test-records --doctype \"Task\"\n\n# profile tests and show a report after tests execute\nbench --site [sitename] run-tests --profile --doctype \"Task\"\n.\n----------------------------------------------------------------------\nRan 1 test in 0.010s\n\nOK\n\n9133 function calls (8912 primitive calls) in 0.011 seconds\n\nOrdered by: cumulative time\n\nncalls tottime percall cumtime percall filename:lineno(function)\n 2 0.000 0.000 0.008 0.004 /home/frappe/frappe-bench/apps/frappe/frappe/model/document.py:187(insert)\n 1 0.000 0.000 0.003 0.003 /home/frappe/frappe-bench/apps/frappe/frappe/model/document.py:386(_validate)\n 13 0.000 0.000 0.002 0.000 /home/frappe/frappe-bench/apps/frappe/frappe/database.py:77(sql)\n 255 0.000 0.000 0.002 0.000 /home/frappe/frappe-bench/apps/frappe/frappe/model/base_document.py:91(get)\n 12 0.000 0.000 0.002 0.000\n\n# verbose log level for tests\nbench --site [sitename] --verbose run-tests\n\nRunning Tests Parallelly\n\nAs the number of tests grows in the project, it takes a long time for tests to complete if it runs serially on one machine.\nRunning tests in parallel across many test machines can save time in Continuous Integration (CI).\n\nParallel Tests\n\nCommand:\n\nbench --site [sitename] --app [app-name] run-parallel-tests --build-id <build-number> --total-build <total-number-of-builds>\n\nUsage:\n\nIf you want to run tests across 2 CI instances your command will be as follows:\n\n# in first CI instance\nbench --site [sitename] run-parallel-tests --build-id 1 --total-builds 2\n\n# in second CI instance\nbench --site [sitename] run-parallel-tests --build-id 2 --total-builds 2\n\nNote: The command will split all test files into 2 parts and execute them in those CI instances.\nThe first half of the test list will be executed in the first instance and the second half of the test list will be executed in the second instance.\n\nParallel tests with orchestrator\n\nIt may happen that each test takes a different amount of time for completion which may result in imbalanced time across CI builds. To mitigate this you can use test orchestrator which runs the next test based on the availability of CI instance. The command to use the test orchestrator for the parallel test is as follows.\n\nCommand:\n\nbench --site [sitename] --app [app-name] run-parallel-tests --use-orchestrator\n\nUsage:\n\nIf you want to run tests across 2 CI instances your command will be as follows\n\n# in first CI instance\nbench --site [sitename] run-parallel-tests --use-orchestrator\n\n# in second CI instance\nbench --site [sitename] run-parallel-tests --use-orchestrator\n\nNote: Environment variables CI_BUILD_ID and ORCHESTRATOR_URL are required for this command. CI_BUILD_ID is the unique ID that you get for each build run of CI.\nORCHESTRATOR_URL is the publicly accessible URL that you get after hosting the orchestrator.\n\nComparison\n\nFor clarity on how the above variants of parallel test commands may work check the following example.\n\nSuppose there are 4 test files as follows\n\ntest_module_one.py 4 mins (execution time)\ntest_module_two.py 2 mins\ntest_module_three.py 1 min\ntest_module_four.py 1 min\n\nTime required without parallel test command.\n\ntest_module_one.py 4 mins\ntest_module_two.py 2 mins\ntest_module_three.py 1 min\ntest_module_four.py 1 min\n==============================\nTotal Wait Time 8 mins\n\nTime required with the first command that auto splits test files across 2 test instances.\n\n# First instance # Second instance\ntest_module_one.py 4 mins test_module_three.py 1 min\ntest_module_two.py 2 mins test_module_four.py 1 min\n---------------------------- ----------------------------\n 6 mins 2 mins\n\n==============================\nTotal Wait Time 6 mins\n\nIt may happen that the time required with the second command that uses orchestrator which runs tests based on availability across 2 test instances.\n\n# First instance # Second instance\ntest_module_one.py 4 mins test_module_two.py 2 mins\n---------------------------- test_module_three.py 1 mins\n 4 mins test_module_four.py 1 min\n ----------------------------\n 4 mins\n==============================\nTotal Wait Time 4 mins\n\nNote: Only one test file is executed on the first instance because it is busy for 4 mins. By that time, the 2nd instance is able to execute other test files which help in balancing time across builds.",
  "scrapedAt": "2025-10-22T00:04:43.655Z"
}